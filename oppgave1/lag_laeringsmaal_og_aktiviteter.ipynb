{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "937d815b",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/erlingmi/KI_hiof/blob/main/oppgave1/lag_laeringsmaal_og_aktiviteter.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5557e15",
      "metadata": {},
      "source": [
        "# üá≥üá¥ Norwegian Curriculum ‚Üí Learning Goals: Generation + JSON Judge (ChatGPT + Gemini) + Activities + PDF\n",
        "\n",
        "This Colab notebook:\n",
        "1) Reads a **Norwegian curriculum** text (`curriculum.txt`),\n",
        "2) Uses **OpenAI (ChatGPT)** to generate **n** alternative **learning goal** sets,\n",
        "3) Uses **Gemini** to **score** each set and **rank** them, with the judge returning **pure JSON**,\n",
        "4) Uses **OpenAI** again to generate **learning activities** for **each goal** in the **top-ranked** set,\n",
        "5) Exports a **nicely formatted PDF** with the curriculum, top goals, and **full activity text**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "130d2b8b",
      "metadata": {
        "id": "install-deps"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai google-generativeai python-dotenv tenacity reportlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c430bb36",
      "metadata": {
        "id": "imports-keys"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API keys set ‚úì (not displayed)\n"
          ]
        }
      ],
      "source": [
        "import os, json, re, pathlib, csv, time\n",
        "from datetime import datetime\n",
        "from getpass import getpass\n",
        "from typing import List, Tuple, Dict\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "\n",
        "load_dotenv(override=False)\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or getpass('Paste your OPENAI_API_KEY (hidden): ')\n",
        "GEMINI_API_KEY = (os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')\n",
        "                  or getpass('Paste your GEMINI/GOOGLE_API_KEY (hidden): '))\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n",
        "os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n",
        "print('API keys set ‚úì (not displayed)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cef68810",
      "metadata": {},
      "source": [
        "### (Optional) Mount Google Drive and load keys from `.env`\n",
        "```\n",
        "OPENAI_API_KEY=sk-...\n",
        "GEMINI_API_KEY=AIza...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9d76bf52",
      "metadata": {
        "id": "mount-drive"
      },
      "outputs": [],
      "source": [
        "USE_DRIVE = False\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    env_path = '/content/drive/MyDrive/.env'\n",
        "    if os.path.exists(env_path):\n",
        "        load_dotenv(env_path, override=True)\n",
        "        os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', os.environ.get('OPENAI_API_KEY',''))\n",
        "        os.environ['GEMINI_API_KEY'] = os.getenv('GEMINI_API_KEY', os.environ.get('GEMINI_API_KEY',''))\n",
        "        os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY', os.environ.get('GEMINI_API_KEY',''))\n",
        "        print('Loaded keys from Drive .env ‚úì')\n",
        "    else:\n",
        "        print('No .env found in Drive path; using previously provided keys.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0d69f52f",
      "metadata": {
        "id": "config"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configured ‚úì\n"
          ]
        }
      ],
      "source": [
        "# ---------- CONFIG ----------\n",
        "N_SUGGESTIONS = 5\n",
        "GENERATION_MODEL = 'gpt-4o-mini'   # OpenAI (ChatGPT) for generation & activities\n",
        "JUDGE_MODEL = 'gemini-1.5-pro'     # Google Gemini for judging\n",
        "TEMPERATURE = 0.7\n",
        "MAX_TOKENS = 1200\n",
        "GOALS_MIN, GOALS_MAX = 4, 6\n",
        "BASE_DIR = pathlib.Path('suggestions'); BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ALL_SUGGESTIONS_FILE = BASE_DIR / 'all_suggestions.txt'\n",
        "RANKING_CSV = BASE_DIR / 'ranking.csv'\n",
        "RANKING_JSON = BASE_DIR / 'ranking.json'\n",
        "CURRICULUM_PATH = pathlib.Path('curriculum.txt')\n",
        "print('Configured ‚úì')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33c07b17",
      "metadata": {},
      "source": [
        "### Provide your curriculum text file (`curriculum.txt`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ee78f2ac",
      "metadata": {
        "id": "upload-curriculum"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded curriculum (139 chars) ‚úì\n"
          ]
        }
      ],
      "source": [
        "if not CURRICULUM_PATH.exists():\n",
        "    \n",
        "    try:\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            first_name = next(iter(uploaded))\n",
        "            CURRICULUM_PATH = pathlib.Path(first_name)\n",
        "            print(f'Using uploaded file: {CURRICULUM_PATH}')\n",
        "    except Exception:\n",
        "        print('Running outside Colab or file upload canceled. Ensure curriculum.txt exists.')\n",
        "assert CURRICULUM_PATH.exists(), f'Curriculum file not found: {CURRICULUM_PATH}'\n",
        "curriculum_text = CURRICULUM_PATH.read_text(encoding='utf-8')\n",
        "print(f'Loaded curriculum ({len(curriculum_text)} chars) ‚úì')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4df43deb",
      "metadata": {},
      "source": [
        "### Static system prompts (hard-coded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e9cccca7",
      "metadata": {
        "id": "prompts"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompts ready ‚úì\n"
          ]
        }
      ],
      "source": [
        "GENERATION_SYSTEM_PROMPT = (\n",
        "    \"\"\"\n",
        "Du er en norsk fagl√¶rer som jobber med LK20-kompetansem√•l. Oppgaven din er √• lese en kompetansem√•ltekst\n",
        "og bryte den ned til konkrete, observerbare **l√¶ringsm√•l** formulert i klart elevspr√•k (ca. B1‚ÄìC1),\n",
        "passende for vurdering. M√•lene skal:\n",
        "  ‚Ä¢ v√¶re spesifikke og m√•lbare (observerbar atferd/produkt)\n",
        "  ‚Ä¢ starte med handlingsverb (f.eks. ¬´forklare¬ª, ¬´analysere¬ª, ¬´dr√∏fte¬ª, ¬´utforske¬ª, ¬´modellere¬ª, ¬´sammenligne¬ª)\n",
        "  ‚Ä¢ kunne sjekkes p√• under 1‚Äì2 √∏kter (eller peke mot delm√•l i lavere vanskelighetsgrad)\n",
        "  ‚Ä¢ dekke bredden i kompetansem√•let (innhold, ferdigheter, begreper) uten √• kopiere setningene\n",
        "  ‚Ä¢ sorteres fra **viktigst ‚Üí minst viktig** for √• hjelpe prioritering i undervisningen\n",
        "\n",
        "*** Eksempel ***\n",
        "Ta utgangspunkt i f√∏lgende kompetansem√•l fra samfunnsfag etter 10.trinn: utforske hvordan teknologi har v√¶rt og fremdeles er en endringsfaktor, og dr√∏fte innvirkningen teknologien har hatt og har p√• enkeltmennesker, samfunn og natur. Bruk l√¶replanverket LK20 som ramme for √• foresl√• ett eller flere l√¶ringsm√•l som:\n",
        "\n",
        "Er tydelig koblet til form√•let med samfunnsfag og relevante kjerneelementer\n",
        "Er forst√•elige og meningsfulle for elever p√• dette trinnet\n",
        "Er tilpasset elevenes niv√• og kontekst\n",
        "St√∏tter utvikling av relevante grunnleggende ferdigheter i faget\n",
        "Kan knyttes til ett eller flere tverrfaglige temaer, dersom det er relevant\n",
        "Formuler l√¶ringsm√•lene med handlingsorienterte verb (som f.eks. forklare, beskrive, analysere, dr√∏fte, vurdere, sammenligne, bruke), og hold dem konkrete nok til √• kunne vurderes. Skriv dem slik at de er forst√•elige for elever 12 √•r. \n",
        "\n",
        "Eksempel p√• innspill til KI:\n",
        "\n",
        "Kompetansem√•l: \"Dr√∏fte hvordan framstillinger av fortiden, hendelser og grupper har p√•virket og p√•virker folks holdninger og handlinger\" (etter 10. trinn)\n",
        "St√∏tteinformasjon (automatisk eller manuelt lagt inn):\n",
        "Form√•l med faget: Utvikle historisk bevissthet, samfunnsforst√•else og evne til √• delta i demokratiske prosesser\n",
        "Kjerneelement: Undring og utforsking, perspektivmangfald og samfunnskritisk tenking\n",
        "Grunnleggende ferdigheter: Skriving og muntlig formidling av resonnementer, kildekritikk, digitale kilder\n",
        "Tverrfaglig tema: Demokrati og medborgerskap\n",
        "Elevgruppe: 10. trinn, heterogen gruppe, tema: holocaust og rasisme i dag\n",
        "Eksempel p√• resultat fra KI:\n",
        "\n",
        "Forslag til l√¶ringsm√•l:\n",
        "\n",
        "Jeg kan forklare hvordan j√∏deforf√∏lgelsen under andre verdenskrig fortsatt preger holdninger i samfunnet i dag.\n",
        "Jeg kan dr√∏fte hvordan film og b√∏ker har p√•virket hvordan vi ser p√• ulike historiske grupper.\n",
        "Jeg kan bruke kilder for √• analysere hvordan framstillinger av samer har endret seg over tid ‚Äì og hva slags holdninger det kan skape.\n",
        "\n",
        "*** Eksempel p√• Output ***\n",
        "Takk for tydelig instruksjon! Her er et sett med konkrete og elevn√¶re l√¶ringsm√•l som tar utgangspunkt i kompetansem√•let:\n",
        "\n",
        "\"Utforske hvordan teknologi har v√¶rt og fremdeles er en endringsfaktor, og dr√∏fte innvirkningen teknologien har hatt og har p√• enkeltmennesker, samfunn og natur.\"\n",
        "(samfunnsfag etter 10. trinn, LK20)\n",
        "üéØ Forslag til l√¶ringsm√•l (tilpasset 12-√•ringer)\n",
        "Teknologi og hverdagen min:\n",
        "Jeg kan beskrive hvordan teknologi p√•virker min hverdag hjemme, p√• skolen og i fritiden.\n",
        "\n",
        "Jeg kan sammenligne hvordan mine besteforeldre og jeg har brukt teknologi i oppveksten.\n",
        "\n",
        "Teknologi og samfunnet:\n",
        "Jeg kan forklare hvordan ny teknologi har forandret jobber og arbeidsplasser i Norge.\n",
        "\n",
        "Jeg kan dr√∏fte hvordan teknologi kan hjelpe folk ‚Äì og samtidig skape nye utfordringer i samfunnet.\n",
        "\n",
        "Teknologi og naturen:\n",
        "Jeg kan forklare hvordan teknologi har b√•de hjulpet og skadet naturen.\n",
        "\n",
        "Jeg kan vurdere hvordan vi kan bruke teknologi p√• en mer b√¶rekraftig m√•te.\n",
        "\n",
        "Bruke og forst√• informasjon:\n",
        "Jeg kan bruke artikler, videoer og nettsteder til √• finne informasjon om hvordan teknologi har utviklet seg.\n",
        "\n",
        "Jeg kan vurdere om informasjonen jeg finner p√• nettet om teknologi er troverdig.\n",
        "\n",
        "üìò Faglig forankring\n",
        "Form√•l med faget samfunnsfag:\n",
        "\n",
        "Skape forst√•else for hvordan samfunnet fungerer, og hvordan mennesker p√•virker og blir p√•virket av utvikling ‚Äì spesielt teknologisk utvikling.\n",
        "\n",
        "Fremme evne til √• delta i demokratiske prosesser og forst√• b√¶rekraftige valg.\n",
        "\n",
        "Kjerneelementer fra LK20:\n",
        "\n",
        "Undring og utforsking: Elevene stiller sp√∏rsm√•l og unders√∏ker teknologiens rolle i samfunnet.\n",
        "\n",
        "Samfunnskritisk tenking: Elevene ser b√•de fordeler og ulemper ved teknologisk utvikling.\n",
        "\n",
        "B√¶rekraftige samfunn: Teknologiens rolle i klima og milj√∏sp√∏rsm√•l blir sentral.\n",
        "\n",
        "Grunnleggende ferdigheter:\n",
        "\n",
        "Muntlig: Presentere og samtale om teknologiens virkninger.\n",
        "\n",
        "Skriving: Lage rapporter eller tekster om teknologiske endringer.\n",
        "\n",
        "Digitale ferdigheter: S√∏ke etter informasjon og vurdere kilder.\n",
        "\n",
        "Lesing: Forst√• faglige og samfunnsaktuelle tekster.\n",
        "\n",
        "Regning: Tolke tall, grafer eller statistikk om teknologi (valgfritt, kontekstavhengig).\n",
        "\n",
        "Tverrfaglige temaer:\n",
        "\n",
        "B√¶rekraftig utvikling: Forholdet mellom teknologi og naturressurser.\n",
        "\n",
        "Demokrati og medborgerskap: Hvordan teknologi kan styrke eller true rettigheter og deltakelse.\n",
        "\n",
        "Folkehelse og livsmestring: Hvordan teknologi p√•virker helse, sosialt liv og trivsel.\n",
        "\n",
        "√ònsker du ogs√• forslag til vurderingsaktiviteter, tverrfaglige prosjekter eller introduksjonstekst til temaet for elever?\n",
        "\n",
        "Instruksjoner for UTDATA-format (kun dette ‚Äì ingen forklaringstekst):\n",
        "‚Ä¢ En nummerert liste med {GOALS_MIN}‚Äì{GOALS_MAX} l√¶ringsm√•l, ett per linje.\n",
        "‚Ä¢ Hver linje **kun** selve m√•let (ingen ekstra metadata).\n",
        "‚Ä¢ Bruk norsk bokm√•l.\n",
        "\"\"\"\n",
        ").strip()\n",
        "\n",
        "JUDGE_SYSTEM_PROMPT = (\n",
        "    \"\"\"\n",
        "Du er sensor og skal KUN vurdere **kvaliteten** p√• en hel liste med foresl√•tte l√¶ringsm√•l\n",
        "opp mot kompetansem√•l (relevans, dekningsgrad, presisjon) og didaktiske kriterier (klarhet, m√•lbarhet,\n",
        "observ√©rbarhet, progresjon, spr√•k for elever, vurderbarhet). Vurder hele settet under ett.\n",
        "\n",
        "KRAV TIL UTDATA (strengt):\n",
        "Returner KUN gyldig, minifisert JSON uten kodeblokker, kommentarlinjer eller ekstra tekst.\n",
        "Eksakt skjema:\n",
        "{\"score\": <desimaltall 0‚Äì1>, \"begrunnelse\": \"kort setning (maks 1‚Äì2 setninger)\"}\n",
        "\n",
        "‚Ä¢ `score` m√• v√¶re et tall mellom 0 og 1 (float)\n",
        "‚Ä¢ `begrunnelse` skal v√¶re kort og presis\n",
        "‚Ä¢ Ingen annen tekst f√∏r eller etter JSON-objektet\n",
        "\"\"\" ).strip()\n",
        "print('Prompts ready ‚úì')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dc74fc0a",
      "metadata": {
        "id": "helpers"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpers ready ‚úì\n"
          ]
        }
      ],
      "source": [
        "openai_client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
        "genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
        "gemini_model = genai.GenerativeModel(\n",
        "    model_name=JUDGE_MODEL,\n",
        "    system_instruction=JUDGE_SYSTEM_PROMPT,\n",
        "    generation_config={'response_mime_type': 'application/json'},\n",
        ")\n",
        "\n",
        "@retry(stop=stop_after_attempt(4), wait=wait_exponential(multiplier=1, min=1, max=20))\n",
        "def call_openai_chat(messages, model=GENERATION_MODEL, temperature=0.7, max_tokens=1200):\n",
        "    return openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "\n",
        "@retry(stop=stop_after_attempt(4), wait=wait_exponential(multiplier=1, min=1, max=20))\n",
        "def call_gemini_judge(prompt: str):\n",
        "    return gemini_model.generate_content(prompt)\n",
        "\n",
        "def generate_one_suggestion(curriculum_text: str) -> str:\n",
        "    user_prompt = (\n",
        "        f\"Les kompetansem√•lteksten mellom <KOMPETANSEMAAL>‚Ä¶</KOMPETANSEMAAL> og lag en liste med {GOALS_MIN}‚Äì{GOALS_MAX} l√¶ringsm√•l.\\n\\n\"\n",
        "        f\"<KOMPETANSEMAAL>\\n{curriculum_text}\\n</KOMPETANSEMAAL>\"\n",
        "    )\n",
        "    messages = [\n",
        "        {'role':'system','content': GENERATION_SYSTEM_PROMPT},\n",
        "        {'role':'user',  'content': user_prompt},\n",
        "    ]\n",
        "    resp = call_openai_chat(messages, model=GENERATION_MODEL)\n",
        "    return resp.choices[0].message.content.strip()\n",
        "\n",
        "def write_text(path: pathlib.Path, text: str):\n",
        "    path.write_text(text, encoding='utf-8')\n",
        "\n",
        "def append_text(path: pathlib.Path, text: str):\n",
        "    with path.open('a', encoding='utf-8') as f:\n",
        "        f.write(text)\n",
        "\n",
        "def _extract_json_block(text: str) -> str:\n",
        "    # Already JSON?\n",
        "    try:\n",
        "        json.loads(text); return text\n",
        "    except Exception: pass\n",
        "    # Strip code fences\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'^```(?:json)?\\s*', '', text)\n",
        "    text = re.sub(r'\\s*```$', '', text)\n",
        "    # First {...}\n",
        "    s, e = text.find('{'), text.rfind('}')\n",
        "    if s != -1 and e != -1 and e > s: return text[s:e+1]\n",
        "    return text\n",
        "\n",
        "def score_with_gemini_json(suggestion_text: str) -> Dict[str, str]:\n",
        "    prompt = \"VURDER DETTE FORSLAGET (hele listen av l√¶ringsm√•l) og svar KUN i JSON:\\n\\n\" + suggestion_text\n",
        "    resp = call_gemini_judge(prompt)\n",
        "    raw = (resp.text or '').strip()\n",
        "    payload = _extract_json_block(raw)\n",
        "    try:\n",
        "        data = json.loads(payload)\n",
        "        score = float(data.get('score', 0.0))\n",
        "        note = str(data.get('begrunnelse', ''))\n",
        "    except Exception:\n",
        "        score = 0.0\n",
        "        note = f'Kunne ikke parse JSON. R√•tt svar: {raw[:500]}'\n",
        "        data = {'score': score, 'begrunnelse': note}\n",
        "    return {'score': score, 'begrunnelse': note, 'raw': raw, 'json': data}\n",
        "\n",
        "def rank_scores(scores: List[float]) -> List[Tuple[int, int, float]]:\n",
        "    order = sorted(enumerate(scores, start=1), key=lambda x: x[1], reverse=True)\n",
        "    return [(rank, idx, sc) for rank, (idx, sc) in enumerate(order, start=1)]\n",
        "\n",
        "print('Helpers ready ‚úì')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "74b9861a",
      "metadata": {
        "id": "generate-loop"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating suggestions‚Ä¶\n",
            "Saved suggestions/suggestion_01.txt\n",
            "Saved suggestions/suggestion_02.txt\n",
            "Saved suggestions/suggestion_03.txt\n",
            "Saved suggestions/suggestion_04.txt\n",
            "Saved suggestions/suggestion_05.txt\n",
            "All suggestions consolidated in: suggestions/all_suggestions.txt\n"
          ]
        }
      ],
      "source": [
        "print('Generating suggestions‚Ä¶')\n",
        "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "ALL_SUGGESTIONS_FILE.write_text('', encoding='utf-8')\n",
        "suggestion_paths = []\n",
        "for i in range(1, N_SUGGESTIONS + 1):\n",
        "    text = generate_one_suggestion(curriculum_text)\n",
        "    path = BASE_DIR / f'suggestion_{i:02d}.txt'\n",
        "    write_text(path, text)\n",
        "    suggestion_paths.append(path)\n",
        "    append_text(ALL_SUGGESTIONS_FILE, f'===== SUGGESTION {i} =====\\n{text}\\n\\n')\n",
        "    print(f'Saved {path}')\n",
        "print(f'All suggestions consolidated in: {ALL_SUGGESTIONS_FILE}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "aa4c20eb",
      "metadata": {
        "id": "judge-loop-json"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scoring suggestions with Gemini (JSON)‚Ä¶\n",
            "suggestion_01.txt: score=0.850 ‚Äî L√¶ringsm√•lene er stort sett relevante, klare og m√•lbare, men dekker ikke alle aspekter ved kompetansem√•lene. Noe forbedringspotensial mtp. progresjon og vurderbarhet for noen av m√•lene.\n",
            "suggestion_02.txt: score=0.800 ‚Äî L√¶ringsm√•lene er stort sett relevante, klare og m√•lbare, men dekker ikke alle aspekter ved medborgerskap og kunne v√¶rt mer spesifikke p√• observ√©rbarhet og vurderbarhet.\n",
            "suggestion_03.txt: score=0.850 ‚Äî L√¶ringsm√•lene er stort sett relevante, presise og m√•lbare, med god dekningsgrad av typiske kompetansem√•l knyttet til medborgerskap. Klarhet, progresjon og vurderbarhet er ogs√• bra, men kan forbedres ytterligere ved √• spesifisere noen av m√•lene mer konkret. Spr√•ket er tilpasset elever.\n",
            "suggestion_04.txt: score=0.850 ‚Äî L√¶ringsm√•lene er stort sett relevante, presise og m√•lbare, og dekker sentrale aspekter ved temaet. Det er noe rom for forbedring i observ√©rbarhet og progresjon.\n",
            "suggestion_05.txt: score=0.800 ‚Äî L√¶ringsm√•lene er stort sett relevante, presise og m√•lbare, men progresjon og vurderbarhet kan tydeliggj√∏res.\n",
            "\n",
            "Ranking (rank, list_index, score):\n",
            "(1, 1, 0.85)\n",
            "(2, 3, 0.85)\n",
            "(3, 4, 0.85)\n",
            "(4, 2, 0.8)\n",
            "(5, 5, 0.8)\n",
            "\n",
            "Saved ranking to:\n",
            "- suggestions/ranking.csv\n",
            "- suggestions/ranking.json\n"
          ]
        }
      ],
      "source": [
        "print('Scoring suggestions with Gemini (JSON)‚Ä¶')\n",
        "scores, begrunnelser, raws, jsons = [], [], [], []\n",
        "for path in suggestion_paths:\n",
        "    s_text = path.read_text(encoding='utf-8')\n",
        "    result = score_with_gemini_json(s_text)\n",
        "    scores.append(result['score'])\n",
        "    begrunnelser.append(result['begrunnelse'])\n",
        "    raws.append(result['raw'])\n",
        "    jsons.append(result['json'])\n",
        "    print(f\"{path.name}: score={result['score']:.3f} ‚Äî {result['begrunnelse']}\")\n",
        "\n",
        "ranking = rank_scores(scores)\n",
        "print('\\nRanking (rank, list_index, score):')\n",
        "for r in ranking:\n",
        "    print(r)\n",
        "\n",
        "with RANKING_CSV.open('w', newline='', encoding='utf-8') as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow(['rank', 'list_index', 'filename', 'score', 'begrunnelse'])\n",
        "    for rank, idx, sc in ranking:\n",
        "        fname = f'suggestion_{idx:02d}.txt'\n",
        "        w.writerow([rank, idx, fname, f'{sc:.4f}', begrunnelser[idx-1]])\n",
        "\n",
        "with RANKING_JSON.open('w', encoding='utf-8') as f:\n",
        "    json.dump({\n",
        "        'generated': [str(p.name) for p in suggestion_paths],\n",
        "        'scores': scores,\n",
        "        'begrunnelser': begrunnelser,\n",
        "        'ranking': ranking,\n",
        "        'judge_model': JUDGE_MODEL,\n",
        "        'generation_model': GENERATION_MODEL,\n",
        "        'timestamp': timestamp,\n",
        "        'raw_judge_outputs': raws,\n",
        "        'json_judge_outputs': jsons,\n",
        "    }, f, ensure_ascii=False, indent=2)\n",
        "print(f\"\\nSaved ranking to:\\n- {RANKING_CSV}\\n- {RANKING_JSON}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1abf9e32",
      "metadata": {},
      "source": [
        "## Generate learning activities for the **top-ranked** suggestion set\n",
        "\n",
        "This cell reads the highest-scoring `suggestion_XX.txt`, parses the learning goals,\n",
        "and asks **the same OpenAI model** to propose concrete learning activities for **each goal**.\n",
        "\n",
        "**Output:**\n",
        "- `suggestions/activities/activities_for_suggestion_XX.md` (all goals aggregated)\n",
        "- `suggestions/activities/activities_goal_YY.md` (one file per goal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "acb0aa74",
      "metadata": {
        "id": "activities-generation"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved aggregated activities to: suggestions/activities/activities_for_suggestion_01.md\n",
            "Per-goal files are in: suggestions/activities\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Directory for activities\n",
        "ACTIVITIES_DIR = BASE_DIR / \"activities\"\n",
        "ACTIVITIES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def generate_activities_for_goal(goal: str, n: int = 5) -> str:\n",
        "    \"\"\"Use the same OpenAI model to propose activities for one learning goal.\n",
        "    Returns Markdown text with a numbered list of activities.\n",
        "    \"\"\"\n",
        "    SYSTEM = (\n",
        "        \"Du er en erfaren norsk fagl√¶rer. Du skal foresl√• konkrete l√¶ringsaktiviteter som hjelper elever √• n√• et gitt l√¶ringsm√•l. \"\n",
        "        \"Lag b√•de individuelle og samarbeidsaktiviteter (bland gjerne). Aktivitetene trenger ikke √• v√¶re digitale. \"\n",
        "        \"For hver aktivitet: gi en kort tittel, skriv en presis beskrivelse, forklar hva elevene l√¶rer, hva l√¶reren b√∏r forberede, og foresl√• kort vurdering. \"\n",
        "        \"Svar p√• norsk bokm√•l og i Markdown som en nummerert liste.\"\n",
        "    )\n",
        "    USER = (\n",
        "        f\"L√¶ringsm√•l: {goal}\\n\\n\" \n",
        "        f\"Gi meg {n} forslag til l√¶ringsaktiviteter (b√•de individuelle og samarbeidsaktiviteter) som kan hjelpe elevene med √• oppn√• dette m√•let. \"\n",
        "        \"Forklar hva elevene l√¶rer i aktiviteten, og hva jeg som l√¶rer b√∏r tenke p√• i forberedelsene.\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM},\n",
        "        {\"role\": \"user\", \"content\": USER},\n",
        "    ]\n",
        "    resp = call_openai_chat(messages, model=GENERATION_MODEL, temperature=0.6, max_tokens=1000)\n",
        "    return resp.choices[0].message.content.strip()\n",
        "\n",
        "# Determine top-ranked suggestion file\n",
        "try:\n",
        "    top_rank, top_idx, top_score = ranking[0]\n",
        "except Exception:\n",
        "    # Fallback: load from file if the scoring cell hasn't been run in this session\n",
        "    data = json.loads(RANKING_JSON.read_text(encoding=\"utf-8\"))\n",
        "    top_idx = data[\"ranking\"][0][1]\n",
        "    top_score = data[\"ranking\"][0][2]\n",
        "\n",
        "top_file = BASE_DIR / f\"suggestion_{top_idx:02d}.txt\"\n",
        "assert top_file.exists(), f\"Top suggestion file not found: {top_file}\"\n",
        "\n",
        "# Parse goals from the top file (strip numbering like '1) ', '2. ', etc.)\n",
        "raw_goals = top_file.read_text(encoding=\"utf-8\").splitlines()\n",
        "goals = []\n",
        "for line in raw_goals:\n",
        "    s = line.strip()\n",
        "    if not s:\n",
        "        continue\n",
        "    s = re.sub(r\"^\\s*\\d+\\s*[\\).:-]?\\s*\", \"\", s)\n",
        "    if s:\n",
        "        goals.append(s)\n",
        "\n",
        "agg_path = ACTIVITIES_DIR / f\"activities_for_{top_file.stem}.md\"\n",
        "with agg_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(f\"# L√¶ringsaktiviteter for {top_file.name} (score={top_score:.3f})\\n\\n\")\n",
        "    for i, goal in enumerate(goals, start=1):\n",
        "        f.write(f\"## L√¶ringsm√•l {i}: {goal}\\n\\n\")\n",
        "        md = generate_activities_for_goal(goal, n=5)\n",
        "        f.write(md + \"\\n\\n\")\n",
        "        # Save per-goal file as well\n",
        "        (ACTIVITIES_DIR / f\"activities_goal_{i:02d}.md\").write_text(\n",
        "            f\"# L√¶ringsm√•l: {goal}\\n\\n\" + md + \"\\n\", encoding=\"utf-8\"\n",
        "        )\n",
        "        time.sleep(1)\n",
        "\n",
        "print(f\"Saved aggregated activities to: {agg_path}\")\n",
        "print(f\"Per-goal files are in: {ACTIVITIES_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1106f908",
      "metadata": {},
      "source": [
        "## Export a nicely formatted PDF (full activity text)\n",
        "\n",
        "This version includes the **full text** of each activity item (title + details),\n",
        "not just the first line. It parses each numbered activity block and prints all lines.\n",
        "\n",
        "**Output:** `suggestions/report_learning_goals_activities.pdf`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "90984002",
      "metadata": {
        "id": "export-pdf-full"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDF saved to: suggestions/report_learning_goals_activities.pdf\n"
          ]
        }
      ],
      "source": [
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.platypus import (\n",
        "    SimpleDocTemplate, Paragraph, Spacer, PageBreak,\n",
        "    ListFlowable, ListItem, KeepTogether\n",
        ")\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib.enums import TA_CENTER\n",
        "from reportlab.lib.units import cm\n",
        "from reportlab.lib import colors\n",
        "from datetime import datetime\n",
        "from xml.sax.saxutils import escape\n",
        "\n",
        "import re, json\n",
        "\n",
        "PDF_PATH = BASE_DIR / 'report_learning_goals_activities.pdf'\n",
        "ACTIVITIES_DIR = BASE_DIR / 'activities'\n",
        "\n",
        "# Resolve top-ranked suggestion\n",
        "try:\n",
        "    top_rank, top_idx, top_score = ranking[0]\n",
        "except Exception:\n",
        "    data = json.loads(RANKING_JSON.read_text(encoding='utf-8'))\n",
        "    top_idx = data['ranking'][0][1]\n",
        "    top_score = data['ranking'][0][2]\n",
        "\n",
        "top_file = BASE_DIR / f'suggestion_{top_idx:02d}.txt'\n",
        "agg_md = ACTIVITIES_DIR / f'activities_for_{top_file.stem}.md'\n",
        "assert top_file.exists(), f'Top suggestion file not found: {top_file}'\n",
        "assert agg_md.exists(), f'Aggregated activities file not found (run the activities cell first): {agg_md}'\n",
        "\n",
        "# Read inputs\n",
        "goals_text = top_file.read_text(encoding='utf-8')\n",
        "activities_md = agg_md.read_text(encoding='utf-8')\n",
        "curriculum_txt = CURRICULUM_PATH.read_text(encoding='utf-8')\n",
        "\n",
        "# Styles\n",
        "styles = getSampleStyleSheet()\n",
        "styles.add(ParagraphStyle(name='TitleCenter', parent=styles['Title'], alignment=TA_CENTER, spaceAfter=12))\n",
        "styles.add(ParagraphStyle(name='H2', parent=styles['Heading2'], spaceBefore=12, spaceAfter=6, textColor=colors.HexColor('#0b5394')))\n",
        "styles.add(ParagraphStyle(name='H3', parent=styles['Heading3'], spaceBefore=10, spaceAfter=4, textColor=colors.HexColor('#38761d')))\n",
        "styles.add(ParagraphStyle(name='Body', parent=styles['BodyText'], leading=14))\n",
        "styles.add(ParagraphStyle(name='Small', parent=styles['BodyText'], fontSize=8, textColor=colors.grey))\n",
        "\n",
        "\n",
        "def para(text, style='Body'):\n",
        "    # Escape user/LLM text so stray < > & don't break the XML\n",
        "    s = escape(text)\n",
        "    # Minimal markdown ‚Üí XML: **bold**, *italics*\n",
        "    s = re.sub(r\"\\*\\*(.+?)\\*\\*\", r\"<b>\\1</b>\", s)\n",
        "    s = re.sub(r\"(?<!\\*)\\*(?!\\*)(.+?)(?<!\\*)\\*(?!\\*)\", r\"<i>\\1</i>\", s)\n",
        "    return Paragraph(s.replace(\"\\n\", \"<br/>\"), styles[style])\n",
        "\n",
        "\n",
        "def para(text, style='Body'):\n",
        "    # Light markdown ‚Üí XML: bold **text**; italics *text*\n",
        "    text = re.sub(r\"\\*\\*(.+?)\\*\\*\", r\"<b>\\1</b>\", text)\n",
        "    text = re.sub(r\"(?<!\\*)\\*(?!\\*)(.+?)(?<!\\*)\\*(?!\\*)\", r\"<i>\\1</i>\", text)\n",
        "    return Paragraph(text.replace('\\n', '<br/>'), styles[style])\n",
        "\n",
        "def parse_numbered_lines(text):\n",
        "    items = []\n",
        "    for line in text.splitlines():\n",
        "        s = line.strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        m = re.match(r'^\\d+\\s*[\\).:-]?\\s+(.*)$', s)\n",
        "        if m:\n",
        "            items.append(m.group(1).strip())\n",
        "    return items\n",
        "\n",
        "def markdown_sections(md):\n",
        "    sections = []\n",
        "    current_h = None\n",
        "    buf = []\n",
        "    for line in md.splitlines():\n",
        "        if line.startswith('## '):\n",
        "            if current_h is not None:\n",
        "                sections.append((current_h, '\\n'.join(buf).strip()))\n",
        "            current_h = line[3:].strip()\n",
        "            buf = []\n",
        "        else:\n",
        "            buf.append(line)\n",
        "    if current_h is not None:\n",
        "        sections.append((current_h, '\\n'.join(buf).strip()))\n",
        "    return sections\n",
        "\n",
        "def split_numbered_blocks(md):\n",
        "    \"\"\"Split a markdown numbered list into blocks (full text per item).\"\"\"\n",
        "    lines = md.splitlines()\n",
        "    blocks = []\n",
        "    buf = []\n",
        "    def is_start(l):\n",
        "        return re.match(r'^\\s*\\d+\\s*[\\).:-]?\\s+\\S', l) is not None\n",
        "    for i, line in enumerate(lines):\n",
        "        if is_start(line):\n",
        "            if buf:\n",
        "                blocks.append('\\n'.join(buf).strip())\n",
        "                buf = []\n",
        "            first = re.sub(r'^\\s*\\d+\\s*[\\).:-]?\\s+', '', line, count=1)\n",
        "            buf.append(first)\n",
        "        else:\n",
        "            buf.append(line)\n",
        "    if buf:\n",
        "        blocks.append('\\n'.join(buf).strip())\n",
        "    return [b for b in blocks if b.strip()]\n",
        "\n",
        "def split_title_and_details(block):\n",
        "    lines = [l for l in block.splitlines() if l.strip()]\n",
        "    if not lines:\n",
        "        return (\"Aktivitet\", \"\")\n",
        "    title = lines[0].strip()\n",
        "    details = '\\n'.join(lines[1:]).strip()\n",
        "    return (title, details)\n",
        "\n",
        "# Build PDF\n",
        "doc = SimpleDocTemplate(str(PDF_PATH), pagesize=A4,\n",
        "                        leftMargin=2*cm, rightMargin=2*cm, topMargin=2*cm, bottomMargin=2*cm)\n",
        "story = []\n",
        "\n",
        "# Cover\n",
        "story.append(para('L√¶ringsm√•l og aktiviteter', 'TitleCenter'))\n",
        "story.append(para(datetime.now().strftime('%Y-%m-%d %H:%M'), 'Small'))\n",
        "story.append(Spacer(1, 12))\n",
        "story.append(para(f\"Generasjonsmodell: <b>{GENERATION_MODEL}</b> ‚Äî Vurderingsmodell: <b>{JUDGE_MODEL}</b>\", 'Small'))\n",
        "story.append(Spacer(1, 18))\n",
        "story.append(para('<b>Kompetansem√•l (kilde)</b>', 'H2'))\n",
        "story.append(para(curriculum_txt, 'Body'))\n",
        "story.append(PageBreak())\n",
        "\n",
        "# Top-ranked goals\n",
        "story.append(para(f'Topprangert l√¶ringsm√•lsliste (suggestion_{top_idx:02d}.txt) ‚Äî score {top_score:.3f}', 'H2'))\n",
        "goals_items = parse_numbered_lines(goals_text)\n",
        "if goals_items:\n",
        "    lst = ListFlowable([ListItem(para(it, 'Body')) for it in goals_items], bulletType='1', start='1', leftIndent=18)\n",
        "    story.append(lst)\n",
        "else:\n",
        "    story.append(para(goals_text, 'Body'))\n",
        "\n",
        "story.append(PageBreak())\n",
        "story.append(para('Forsl√•tte l√¶ringsaktiviteter per l√¶ringsm√•l', 'H2'))\n",
        "\n",
        "sections = markdown_sections(activities_md)\n",
        "for heading, body in sections:\n",
        "    story.append(para(heading, 'H3'))\n",
        "    blocks = split_numbered_blocks(body)  # full block per numbered item\n",
        "    if blocks:\n",
        "        items = []\n",
        "        for block in blocks:\n",
        "            title, details = split_title_and_details(block)\n",
        "            full_text = f\"**{title}**\"\n",
        "            if details:\n",
        "                full_text += \"\\n\" + details  # keep all lines\n",
        "            # IMPORTANT: no KeepTogether here\n",
        "            items.append(ListItem(para(full_text, 'Body')))\n",
        "        lst = ListFlowable(items, bulletType='1', start='1', leftIndent=18)\n",
        "        story.append(lst)\n",
        "    else:\n",
        "        story.append(para(body, 'Body'))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "\n",
        "doc.build(story)\n",
        "print(f'PDF saved to: {PDF_PATH}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcdfa3db",
      "metadata": {},
      "source": [
        "## Outputs\n",
        "- `suggestions/suggestion_XX.txt` (each list)\n",
        "- `suggestions/all_suggestions.txt`\n",
        "- `suggestions/ranking.csv` and `ranking.json` (include **begrunnelse**)\n",
        "- `suggestions/activities/*.md` (activities per goal and aggregated)\n",
        "- `suggestions/report_learning_goals_activities.pdf` (full activity text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Norwegian Curriculum ‚Üí Learning Goals (JSON Judge + Activities + PDF).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
